# Scrapy Quote Tutorial
This is a scrapy tutorial project to create a spider crawler and gather data from 2 connected pages individually for each records. 
## Getting Started with the codebase
Clone this repository
## Installing Essentials
`requirements.txt` file contains all the needed libraries. You can simply pip install them from the directory containing the requirements file. I would highly recommend to use virtual env before doing any pip innstak
```
pip install -r requirements.txt
```
## Follow the guide next
For a step by step guide from creation of the spider crawler to implementing multipage scraper checkout our blog at https://thecodework.com/blog/spider-crawling-for-data-scraping-with-python-and-scrapy/

If you need any help or have any query, do reach out to me at https://thecodework.com/contact-us/

## ðŸŽ‰ Happy Scraping. ðŸŽ‰